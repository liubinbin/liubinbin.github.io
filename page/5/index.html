<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>BIN</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="BIN">
<meta property="og:url" content="http://example.com/page/5/index.html">
<meta property="og:site_name" content="BIN">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="binbin liu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="BIN" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">BIN</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">a blog of bin</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-DFSOutputStream-analysis" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/10/18/DFSOutputStream-analysis/" class="article-date">
  <time class="dt-published" datetime="2017-10-18T14:59:00.000Z" itemprop="datePublished">2017-10-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/10/18/DFSOutputStream-analysis/">DFSOutputStream分析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>private void waitAndQueueCurrentPacket()<br>调用者：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">flushOrSync</span><span class="params">(<span class="type">boolean</span> isSync, EnumSet&lt;SyncFlag&gt; syncFlags)</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">writeChunk</span><span class="params">(<span class="type">byte</span>[] b, <span class="type">int</span> offset, <span class="type">int</span> len, <span class="type">byte</span>[] checksum)</span> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span></span><br></pre></td></tr></table></figure>
<p>public class DFSOutputStream extends FSOutputSummer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">implements</span> <span class="title class_">Syncable</span>, CanSetDropBehind &#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> LinkedList&lt;Packet&gt; dataQueue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;Packet&gt;(); <span class="comment">// dataQueue是数据队列，用于保存等待发送给datanode的数据包</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> LinkedList&lt;Packet&gt; ackQueue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;Packet&gt;(); <span class="comment">// ackQueue是确认队列，保存还没有被datanode确认接收的数据包</span></span><br><span class="line">	<span class="keyword">private</span> DataStreamer streamer;  <span class="comment">// streamer线程，不停的从dataQueue中取出数据包，发送给datanode</span></span><br><span class="line">	...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DataStreamer</span> <span class="keyword">extends</span> <span class="title class_">Daemon</span> &#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">boolean</span> <span class="variable">streamerClosed</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">	<span class="keyword">private</span> ExtendedBlock block; <span class="comment">// its length is number of bytes acked</span></span><br><span class="line">	<span class="keyword">private</span> Token&lt;BlockTokenIdentifier&gt; accessToken;</span><br><span class="line">	<span class="keyword">private</span> DataOutputStream blockStream; <span class="comment">// socket的输出流(client-&gt;datanode)，用于将数据传输给datanode</span></span><br><span class="line">	<span class="keyword">private</span> DataInputStream blockReplyStream; <span class="comment">// socket的输入流(datanode-&gt;client)，用户收到datanode的确认包</span></span><br><span class="line">	<span class="keyword">private</span> <span class="type">ResponseProcessor</span> <span class="variable">response</span> <span class="operator">=</span> <span class="literal">null</span>; <span class="comment">// response线程，用于接收从datanode返回的反馈信息</span></span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>block &gt; packet &gt; chunk(带chunksum)<br>​		<br>主要看看writeChunk方法。</p>
<ol>
<li>构造currentPacket，写入data和checksum，并且的chunk数++，bytesCurBlock增加数据的长度。</li>
<li>如果chunk数足够多。则调用waitAndQueueCurrentPacket</li>
<li>如果如果block的大小足够大的话，</li>
</ol>
<p>其中一个处理时添加chunk到缓存中。一下具体处理为判断是否可以添加入发送给datanode的缓存中。lastQueuedSeqno保存了最后一个需要处理的序号。<br>&#x2F;**</p>
<ul>
<li>如果没有足够空间话就等待，然后<br> *&#x2F;<br> ​  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">waitAndQueueCurrentPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line"> 	<span class="keyword">try</span> &#123;</span><br><span class="line"> 		<span class="comment">// If queue is full, then wait till we have enough space</span></span><br><span class="line"> 		<span class="keyword">while</span> (!closed &amp;&amp; dataQueue.size() + ackQueue.size()  &gt; MAX_PACKETS) &#123;</span><br><span class="line">   			<span class="keyword">try</span> &#123;</span><br><span class="line"> 				dataQueue.wait();</span><br><span class="line">      		&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      			Thread.currentThread().interrupt();</span><br><span class="line"> 				<span class="keyword">break</span>;</span><br><span class="line">        	&#125;</span><br><span class="line"> 	&#125;</span><br><span class="line"> 	checkClosed();</span><br><span class="line"> 	queueCurrentPacket();</span><br><span class="line"> 	&#125; <span class="keyword">catch</span> (ClosedChannelException e) &#123;</span><br><span class="line">	...</span><br><span class="line"> 	&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  &#x2F;**</li>
<li>添加dataQueue，设置lastQueuedSeqno<br> *&#x2F;<br> ​  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">queueCurrentPacket</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">		<span class="keyword">if</span> (currentPacket == <span class="literal">null</span>) <span class="keyword">return</span>;</span><br><span class="line">		dataQueue.addLast(currentPacket);</span><br><span class="line">		lastQueuedSeqno = currentPacket.seqno;  <span class="comment">//在waitForAckedSeqno方法使用，判断是否所有数据都被写入并接受到ack了。</span></span><br><span class="line">		<span class="keyword">if</span> (DFSClient.LOG.isDebugEnabled()) &#123;</span><br><span class="line">			DFSClient.LOG.debug(<span class="string">&quot;Queued packet &quot;</span> + currentPacket.seqno);</span><br><span class="line">		&#125;</span><br><span class="line">		currentPacket = <span class="literal">null</span>;</span><br><span class="line">		dataQueue.notifyAll();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  ​</li>
</ul>
<p>DataStreamer是处理添加入缓存dataQueue的数据。将他们发送然后添加到ackQueue中。<br>在while中有processDatanodeError的处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">  <span class="comment">// move packet from dataQueue to ackQueue</span></span><br><span class="line">  <span class="keyword">if</span> (!one.isHeartbeatPacket()) &#123;</span><br><span class="line">    dataQueue.removeFirst();</span><br><span class="line">    ackQueue.addLast(one);</span><br><span class="line">    dataQueue.notifyAll();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// write out data to remote datanode</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  one.writeTo(blockStream);</span><br><span class="line">  blockStream.flush();   </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">还需要一个线程接受ack，为ResponseProcessor</span><br><span class="line"><span class="comment">//获取返回的序号</span></span><br><span class="line">ack.readFields(blockReplyStream);</span><br><span class="line"><span class="type">long</span> <span class="variable">seqno</span> <span class="operator">=</span> ack.getSeqno();</span><br><span class="line"><span class="comment">//获取dataQueue里第一个包的序号</span></span><br><span class="line">Packet one;</span><br><span class="line"><span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">  one = ackQueue.getFirst();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (one.seqno != seqno) &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IOException</span>(<span class="string">&quot;ResponseProcessor: Expecting seqno &quot;</span> +</span><br><span class="line">                        <span class="string">&quot; for block &quot;</span> + block +</span><br><span class="line">                        one.seqno + <span class="string">&quot; but received &quot;</span> + seqno);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//移除ackQueuede里的第一个，</span></span><br><span class="line"><span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">  lastAckedSeqno = seqno; <span class="comment">//lastAckedSeqno在waitForAckedSeqno有使用</span></span><br><span class="line">  ackQueue.removeFirst();</span><br><span class="line">  dataQueue.notifyAll();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>toWaitFor &#x3D; lastQueuedSeqno;<br>waitForAckedSeqno(toWaitFor)在flushInternal和flushOrSync会调用。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/10/18/DFSOutputStream-analysis/" data-id="clyh80jio0001s26080wj8s90" data-title="DFSOutputStream分析" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hdfs/" rel="tag">hdfs</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-a-special-case-about-rwlock" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/10/08/a-special-case-about-rwlock/" class="article-date">
  <time class="dt-published" datetime="2017-10-08T12:31:28.000Z" itemprop="datePublished">2017-10-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/10/08/a-special-case-about-rwlock/">一个奇怪的rwlock锁卡住的case</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>遇到一个case，有关于读写锁。原因路径如下：</p>
<ol>
<li>线上有一个datanode节点宕机，导致与此节点的连接出现问题。</li>
<li>有hdfs客户端进程在处理此连接超时部分的代码有问题，没有将外层的超市传入至底层socket里，出问题的线程持有了无法超市推出，一直hang住，此线程还持有了一个读写锁的读锁。</li>
<li>由于内部某些机制另一个线程需要写锁，同时此锁的读锁会不停有人由于请求需要拿到和释放。</li>
<li>这时候出现了其他线程的读锁也无法获取到。</li>
</ol>
<p>从线程栈看，就是一个线程获取了读锁，阻塞了别的线程获取读锁和写锁。</p>
<p>还原现场例子代码地址：<a target="_blank" rel="noopener" href="https://github.com/liubinbin/sta/tree/master/rwlock/src/rwlock">https://github.com/liubinbin/sta/tree/master/rwlock/src/rwlock</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">看看ReentrantReadWriteLock，注意构造函数里可以传一个布尔值，区分公平锁和非公平锁。</span><br></pre></td></tr></table></figure>

<p>NonfairSync和FairSync分别是两种实现，其中都实现了readerShouldBlock方法。这问题分两种情况：</p>
<ol>
<li>公平锁：这种情况下对AQS的请求是需要安装时间顺序，如果新来的读请求在写请求之后就需要等待。</li>
<li>非公平锁：为了防止写请求饥饿，读请求会先判断等待队列头是否是写请求，所以在这种情况下，写请求会隔离读锁和读锁。</li>
</ol>
<p>此问题最后解决办法是让那个出问题的读锁尽快的释放，不要一直占着读锁就可以把影响降低。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/10/08/a-special-case-about-rwlock/" data-id="clyh80jiq0004s2601ozb8sqp" data-title="一个奇怪的rwlock锁卡住的case" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java-concurrent/" rel="tag">java, concurrent</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-docker-basics" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/08/25/docker-basics/" class="article-date">
  <time class="dt-published" datetime="2017-08-25T14:22:15.000Z" itemprop="datePublished">2017-08-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/08/25/docker-basics/">最近使用docker的一些小记录</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>mysql出了需要grant之外，还要修改bind-address</p>
<p>docker 基本命令</p>
<p>docker 中container基于image制作，image类似一个模版，基于某个image制作的contaner都具有和image一样的内容</p>
<p>我们可以根据REPOSITORY来判断这个镜像是来自哪个服务器，如果没有 &#x2F; 则表示官方镜像，并且在search的时候会标有OFFICIAL，类似于ip:port&#x2F;repos_name则表示的是私服。</p>
<p>docker pull username&#x2F;repository&lt;:tag_name&gt; 或者 docker pull repository，pull和push相对应。</p>
<h4 id="5-2-运行出一个container放到后台运行"><a href="#5-2-运行出一个container放到后台运行" class="headerlink" title="5.2 运行出一个container放到后台运行"></a>5.2 运行出一个container放到后台运行</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># docker run -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 2; done&quot;</span><br><span class="line">ae60c4b642058fefcc61ada85a610914bed9f5df0e2aa147100eab85cea785dc</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>它将直接把启动的container挂起放在后台运行（这才叫saas），并且会输出一个<code>CONTAINER ID</code>，通过<code>docker ps</code>可以看到这个容器的信息，可在container外面查看它的输出<code>docker logs ae60c4b64205</code>，也可以通过<code>docker attach ae60c4b64205</code>连接到这个正在运行的终端，此时在<code>Ctrl+C</code>退出container就消失了，按ctrl-p ctrl-q可以退出到宿主机，而保持container仍然在运行</p>
<p>端口映射</p>
<p>Docker中运行的程序的端口是不能直接访问的，需要映射到本地，通过-p参数实现，例如将6379端口映射到本机的6378端口</p>
<p>容器日志</p>
<p>查看当前容器的日志</p>
<p><code>docker logs container-name/container-id</code></p>
<p>我们可以查看之前redis镜像的容器</p>
<p><code>docker logs test-redis</code></p>
<p>可以看到redis启动的日志</p>
<p>运行中的容器其实就是一个完备的Linux操作系统，我们可以登录访问当前容器，登录后可以在容器中进行常规的Linux操作。<br><code>docker exec -it container-id/container-name bash</code></p>
<p>系统版本</p>
<p>[root@bogon yum.repos.d]# uname -a<br>Linux bogon 2.6.32-642.el6.x86_64 #1 SMP Tue May 10 17:27:01 UTC 2016 x86_64 x86_64 x86_64 GNU&#x2F;Linux<br>[root@bogon yum.repos.d]# cat &#x2F;etc&#x2F;redhat-release<br>CentOS release 6.8 (Final)</p>
<p>安装EPEL</p>
<p>因为系统自带的repo中不带docker需要安装epel</p>
<p>rpm -Uvh <a target="_blank" rel="noopener" href="http://ftp.riken.jp/Linux/fedora/epel/6Server/x86_64/epel-release-6-8.noarch.rpm">http://ftp.riken.jp/Linux/fedora/epel/6Server/x86_64/epel-release-6-8.noarch.rpm</a></p>
<p>安装Docker</p>
<p>yum install -y docker-io</p>
<p>开机自启动与启动Docker</p>
<p>[root@bogon yum.repos.d]# service docker start<br>Starting cgconfig service:                                 [  OK  ]<br>Starting docker:                                       [  OK  ]<br>[root@bogon yum.repos.d]# chkconfig docker on<br>[root@bogon yum.repos.d]# chkconfig docker –list<br>docker          0:off   1:off   2:on    3:on    4:on    5:on    6:off<br>[root@bogon yum.repos.d]# </p>
<p>至此docker已经安装完成</p>
<p>docker rm 删除container</p>
<p>docker rmi 删除image</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/permike/article/details/51879578">http://blog.csdn.net/permike/article/details/51879578</a> 总结的非常好</p>
<p>已完成<br>docker pull morrisjobke&#x2F;docker-swift-onlyone<br>docker pull kahing&#x2F;docker-swift<br>docker pull debian</p>
<p>docker pull [选项] [Docker Registry 地址[:端口号]&#x2F;]仓库名[:标签]</p>
<p>启动container<br>  docker run -d -P -v &#x2F;srv&#x2F;node&#x2F;sdb1&#x2F;docker&#x2F;:&#x2F;swift&#x2F;nodes -t bouncestorage&#x2F;swift-aio<br>通过docker ps 获取端口<br>然后通过<a target="_blank" rel="noopener" href="http://127.0.0.1/">http://127.0.0.1</a>:<port>&#x2F;auth&#x2F;v1.0 进行系统的操作和访问<br>具体的命令形式如下<br>  swift -A <a target="_blank" rel="noopener" href="http://127.0.0.1:32770/auth/v1.0">http://127.0.0.1:32770/auth/v1.0</a> -U test:tester -K testing</p>
<p>swift-aio-docker</p>
<p>docker run -it –rm debian bash<br>  -it: 这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。<br>  –rm: 这个参数是说容器退出后随之将其删除</p>
<p><code>bash</code>：放在镜像名后的是<strong>命令</strong>，这里我们希望有个交互式 Shell</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]</span><br></pre></td></tr></table></figure>

<p>Docker Registry 地址[:端口号] 默认docker hub</p>
<p>仓库名为<code>&lt;用户名&gt;/&lt;软件名&gt;</code> ，默认为 <code>library</code></p>
<p>latest为默认标签<br>​	</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/08/25/docker-basics/" data-id="clyh80jiq0008s2608w347x5i" data-title="最近使用docker的一些小记录" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/life/" rel="tag">life</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-some-thoughts" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/08/25/some-thoughts/" class="article-date">
  <time class="dt-published" datetime="2017-08-25T14:22:15.000Z" itemprop="datePublished">2017-08-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/08/25/some-thoughts/">最近感想</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>最近在读萨缪尔森的《经济学》，其实很早此书就在淘宝的购物车里，一直没有买来读。大概是自己懒的原因吧。整本书很大并且很厚，很有教材的感觉，读完真的很累，但是觉得很值。现在渐渐感觉看到一件事，一个政策，一个评论能想到一些东西。</p>
<p>之前微博里在说保险相关的信息，其实我们每个人都应该读点经济学和金融的书，使自己能更好的理解发布的各种信息背后可能隐藏的一些更深层次的信息，以便我们能更好的做出更加理智的判断。</p>
<p><code>点赞</code>学长，前几天下载的《Linux System Prorgramming》中文翻译的pdf是工大的一些学长做的。我真的感慨自己表达出的观点真的太少，并且没有做能影响别人的事情，以后我一定要多在此博客中发表自己的想法，并且希望以后能做一些影响别人的事情，至少是一些有趣的事情。</p>
<h2 id="经济学"><a href="#经济学" class="headerlink" title="经济学"></a>经济学</h2><p>那本书里面其实说了很多原理性的东西，读着很枯燥，但是原理又是理解一切的基础。在那本书中，我最感兴趣的其实是货币政策和财政政策这些部分，那两部分是比较接近有用，能用于生活判断一些东西。</p>
<p>等过段时间像把货币相关的一些东西再找几本书捋一捋，希望可以到时候能更加准确的理解这些事情。等更加理解了之后再写点东西。</p>
<p>大概一个月之前，看了《大逃港》这本书，给我的感觉是，每个人最终应该是为了利益在做事情，一件事情也只有有足够的利益诱惑才能推行直至完成。嗨，不能讲太多，不是很确定line在哪里。</p>
<p>##最近想法</p>
<p>最近看完那本《经济学》之后，越来越感觉自己应该找些事情做。当然基本应该是和计算机相关的，下面列一些最近想到的一些东西。</p>
<h3 id="写一个数据库"><a href="#写一个数据库" class="headerlink" title="写一个数据库"></a>写一个数据库</h3><p>在大学时，个人对数据库其实也挺感兴趣，最近三年的工作其实很多也是和数据库相关。现在的想法是自己写个数据库应该是一件有意思的事情，另一个动因是买了《代码大全》这本书，感觉看完之后应该能够有东西来实践。两者可以结合在一起做。应该是件有意思的事情。</p>
<h3 id="获取跑步路线"><a href="#获取跑步路线" class="headerlink" title="获取跑步路线"></a>获取跑步路线</h3><p>之前在北京的时候，跑步很多时候是在公园进行的。跑完看着那个路线图，如果自己跑了一个2017等数字的形状的，应该是件有意思的事情。</p>
<p>最近稍微想了这个事情，这功能的实现很依赖地图数据的样子。</p>
<h3 id="水果店买水果"><a href="#水果店买水果" class="headerlink" title="水果店买水果"></a>水果店买水果</h3><p>有一次去水果店买东西的时候，店里工作让加入一个群，说里面有各种优惠。到现在也对此种产品信息的推送感觉不是很理想。</p>
<ol>
<li><p>水果店的水果信息没法完全展示在顾客面前，因为每天在群里只能看到一些优惠的水果。</p>
</li>
<li><p>通过每个人把自己想买的东西加入一个列表里，然后在群里不停的发列表。这种方式其实是对店主友好，对群里的顾客不友好。</p>
</li>
<li><p>仔细想这件事，本质很团购或会员卡没什么区别，但是这其中店主和顾客之间信息的交流很不顺畅。</p>
<p>信息的顺畅交流才能更好地提升效率，利用好互联网这个工具和提高营收。</p>
</li>
</ol>
<h3 id="阅读英文查阅的很不方便和音乐软件的割裂"><a href="#阅读英文查阅的很不方便和音乐软件的割裂" class="headerlink" title="阅读英文查阅的很不方便和音乐软件的割裂"></a>阅读英文查阅的很不方便和音乐软件的割裂</h3><p>英文阅读方面，扇贝做的不错。看到有不懂的词汇或词组可以直接长摁然后显示意思，可以非常快的回到阅读中，对整体的阅读流畅性影响不是很大，有一个问题是文章比较尴尬。如果是别的文章质量更加好的app或网址的话，生词查阅方面做的没这么好。</p>
<p>网易云音乐貌似遇到的版权问题，我看了一下我收藏的音乐，基本没有变灰无法听的，突然感觉自己的音乐品味是不是和大众不太一样。</p>
<h3 id="研报，公告的信息获取"><a href="#研报，公告的信息获取" class="headerlink" title="研报，公告的信息获取"></a>研报，公告的信息获取</h3><p>研报和公告信息相对来说比较难。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/08/25/some-thoughts/" data-id="clyh80jiv001ws260hcmt4xdk" data-title="最近感想" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/life/" rel="tag">life</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-vmware-install-centos" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/08/25/vmware-install-centos/" class="article-date">
  <time class="dt-published" datetime="2017-08-25T14:22:15.000Z" itemprop="datePublished">2017-08-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/08/25/vmware-install-centos/">vmware安装centos</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>此文记录自己安装centos时的一些步骤纯粹为了下次安装更加快速的完成，因为在前段时间删除虚拟机之后发现一下子想不起来是怎么安装的centos，需要求助搜索引擎和一步步的探索才能完成。</p>
<h2 id="第0步-安装vmware和下载centos"><a href="#第0步-安装vmware和下载centos" class="headerlink" title="第0步 安装vmware和下载centos"></a>第0步 安装vmware和下载centos</h2><p>下载centos从之前的6版本切换到了7版本，此处为了保持和目前线上机器的版本一致，可以使自己能更适应新版的centos。</p>
<h2 id="第1步-创建centos虚拟机"><a href="#第1步-创建centos虚拟机" class="headerlink" title="第1步 创建centos虚拟机"></a>第1步 创建centos虚拟机</h2><p><img src="/step1.png"></p>
<p>选择Create a custom virtual machine</p>
<p><img src="/step2.png"></p>
<p>选择对应的版本CentOS 64-bit</p>
<p><img src="/step3.png"></p>
<p>选择Create a new virtual disk</p>
<p><img src="/step4.png"></p>
<p>选择Customize Settings，然后选择Save.</p>
<p>然后开始设置配置，主要如下：</p>
<ul>
<li>Processors &amp; Memory	(4core 8G)</li>
<li>Hard Disk (80G)</li>
<li>CD&#x2F;DVD (IDE) (此处一定需要设置，将下载的iso加入配置中，并且需要连接DVD)</li>
</ul>
<p>然后开始安装，更改mini 安装模式，添加gnome桌面，然后进入正常的linux安装界面。之后一切就比较顺利。</p>
<p>最后可能需要安装图形界面：<strong>yum groupinstall</strong> “GNOME Desktop”，重启进入root执行“init 5”</p>
<p>##注意事项</p>
<p>###新版系统需要改变设置</p>
<p>Please check System Preferences &#x3D;&#x3D;&gt;Security&amp;Privacy&#x3D;&#x3D;&gt;Privacy&#x3D;&#x3D;&gt;Accessibility, make sure you have added Fusion into the list.</p>
<p>###键盘切换快捷键：</p>
<p>cmd + G ： 切到虚拟机</p>
<p>cmd + control：切到mac系统</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/08/25/vmware-install-centos/" data-id="clyh80jiw0024s2600sqnatqc" data-title="vmware安装centos" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/life/" rel="tag">life</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-rit-in-HBase" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/05/30/rit-in-HBase/" class="article-date">
  <time class="dt-published" datetime="2017-05-30T12:08:15.000Z" itemprop="datePublished">2017-05-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/05/30/rit-in-HBase/">rit in HBase</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>以前在别人博客中看到看到hbase中RIT的蛋疼，最近也确实感觉这个状态是比较尴尬的，别人会来找你。最近会放一些精力来解析hbase的rit状态，同时也是希望自己能对hbase有更全面和深入的了解。感觉过去两个月对hbase的的检索和加载流程看的比较多了。</p>
<p>遇到一个case：</p>
<p>一个region处于pending_open的状态。</p>
<p>大概逻辑，本来master给某个节点发送open此region的请求，过程进行的很好。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/05/30/rit-in-HBase/" data-id="clyh80jiv001ps2608pim7knb" data-title="rit in HBase" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hbase-src-hfile" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/05/14/hbase-src-hfile/" class="article-date">
  <time class="dt-published" datetime="2017-05-14T02:01:39.000Z" itemprop="datePublished">2017-05-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/05/14/hbase-src-hfile/">HBase源码系列之HFile</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本文讨论0.98版本的hbase里v2版本。其实对于HFile能有一个大体的较深入理解是在我去查看”到底是不是一条记录不能垮block“的时候突然意识到的。</p>
<p>首先说一个对HFile很直观的感觉，我觉得HFile的整个设计中很重要的一点是为减少内容占用。首先写时候可以把一个个block按顺序写入，满足一个chunk写入一个元数据（包括bloomfilter），最后是一些HFile的元数据。对于HFile，我个人觉得主要把握好几个问题。</p>
<ol>
<li>block的组织</li>
<li>bf和block的关系</li>
<li>index和block的关系</li>
<li>写入顺序和一些基本的元数据信息结构</li>
<li>记录能不能跨block</li>
</ol>
<p>明白这四个问题感觉基本可以大致的描绘出HFile了。</p>
<h2 id="HFileWriterV2"><a href="#HFileWriterV2" class="headerlink" title="HFileWriterV2"></a>HFileWriterV2</h2><p>首先，我们知道会引起下HFile的操作有flush和compaction。在此，我们就选择从flush这个入口跟进去看。</p>
<p>在StoreFile中，以下方法主要是为了Store书写到一个HFile中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(InternalScanner scanner, CellSink sink, <span class="type">long</span> smallestReadPoint) <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<p>在此方法会调用如下方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">append</span><span class="params">(<span class="keyword">final</span> KeyValue kv)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="comment">//如下两行主要是来加入到bf中的，下面的这个就是我们经常说的bf索引。</span></span><br><span class="line">  appendGeneralBloomfilter(kv);</span><br><span class="line">  appendDeleteFamilyBloomFilter(kv);</span><br><span class="line">  <span class="comment">//这行是重点</span></span><br><span class="line">  writer.append(kv);</span><br><span class="line">  <span class="comment">//这行先不管，处理时间戳</span></span><br><span class="line">  trackTimestamps(kv);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以下分解append方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//检查key是否有问题，是否按顺序（memstore使用ConcurrentSkipListMap存储，应该不会有此问题）。</span></span><br><span class="line"><span class="comment">//并且返回key是否重复</span></span><br><span class="line"><span class="type">boolean</span> <span class="variable">dupKey</span> <span class="operator">=</span> checkKey(key, koffset, klength);</span><br><span class="line">checkValue(value, voffset, vlength);</span><br><span class="line"><span class="comment">//如果不重复，则不检查边界，答案不能，因为如果有重复，不会检查边界更不会新建一个block。***问题5***</span></span><br><span class="line"><span class="keyword">if</span> (!dupKey) &#123;</span><br><span class="line">  <span class="comment">//此出会检查block的大小，并且有一处需要注意，在里面的代码中有一些记录block信息的，这个以后会有用。</span></span><br><span class="line">  <span class="comment">//此处会写出chunk，处理readyChunks</span></span><br><span class="line">  checkBlockBoundary();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面注释中说的那个代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">byte</span>[] indexKey = comparator.calcIndexKey(lastKeyOfPreviousBlock, firstKeyInBlock);</span><br><span class="line">dataBlockIndexWriter.addEntry(indexKey, lastDataBlockOffset, onDiskSize);</span><br></pre></td></tr></table></figure>

<p>append下面是一些很正常的数据写入（都是对stream的添加操作），元数据记录（firstKeyInBlock）等。</p>
<p>回到appendGeneralBloomfilter(kv)方法，此方法里面有一个判断是值得注意的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在此代码中会判断key的个数，如果key的个数达到了一定程度就新建一个chunk，放入readyChunks（这个会在checkBlockBoundary中处理），此出会写bf。***问题2***</span></span><br><span class="line">enqueueReadyChunk(<span class="literal">false</span>);</span><br><span class="line">... 这种是处理chunk被写出的时候的操作。重置一些值 ...</span><br><span class="line"><span class="comment">//真正的添加到bf中</span></span><br><span class="line">chunk.add(bloomKey, keyOffset, keyLength);</span><br></pre></td></tr></table></figure>

<p>在enqueueReadyChunk(false)中有</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ReadyChunk</span> <span class="variable">readyChunk</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReadyChunk</span>();</span><br><span class="line">readyChunk.chunkId = numChunks - <span class="number">1</span>;</span><br><span class="line">readyChunk.chunk = chunk;</span><br><span class="line">readyChunk.firstKey = firstKeyInChunk; </span><br><span class="line">readyChunks.add(readyChunk);</span><br></pre></td></tr></table></figure>

<p>然后时间很快就到了close环节。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//此处组织了block，将加入到此HFile的chunk生成树的结构。</span></span><br><span class="line"><span class="type">long</span> <span class="variable">rootIndexOffset</span> <span class="operator">=</span> dataBlockIndexWriter.writeIndexBlocks(outputStream);</span><br></pre></td></tr></table></figure>

<p>block组织也分两类，一个chunk里组织block（他们共生存啊，用了一个bf），另外是root index和intermedia index的组织，实际这个更多感觉是组织chunk。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">writeInlineBlocks</span><span class="params">(<span class="type">boolean</span> closing)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="comment">//inlineBlockWriters 应该就3个，两个bf和一个block（待确定）</span></span><br><span class="line">  <span class="keyword">for</span> (InlineBlockWriter ibw : inlineBlockWriters) &#123;</span><br><span class="line">    <span class="keyword">while</span> (ibw.shouldWriteBlock(closing)) &#123;</span><br><span class="line">      <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> outputStream.getPos();</span><br><span class="line">      <span class="type">boolean</span> <span class="variable">cacheThisBlock</span> <span class="operator">=</span> ibw.getCacheOnWrite();</span><br><span class="line">      ibw.writeInlineBlock(fsBlockWriter.startWriting(</span><br><span class="line">          ibw.getInlineBlockType()));</span><br><span class="line">      fsBlockWriter.writeHeaderAndData(outputStream);</span><br><span class="line">      <span class="comment">//此处添加leaf index block</span></span><br><span class="line">      ibw.blockWritten(offset, fsBlockWriter.getOnDiskSizeWithHeader(),</span><br><span class="line">          fsBlockWriter.getUncompressedSizeWithoutHeader());</span><br><span class="line">      totalUncompressedBytes += fsBlockWriter.getUncompressedSizeWithHeader();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (cacheThisBlock) &#123;</span><br><span class="line">        doCacheOnWrite(offset);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ibw.shouldWriteBlock(closing)方法的判断如下，实际是判断是否有chunk</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">shouldWriteBlock</span><span class="params">(<span class="type">boolean</span> closing)</span> &#123;</span><br><span class="line">  enqueueReadyChunk(closing);</span><br><span class="line">  <span class="comment">//readyChunks中保存的是chunk，也就是lead index block</span></span><br><span class="line">  <span class="keyword">return</span> !readyChunks.isEmpty();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面是写入bloom meta index，感觉就是chunk的那些。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bloomBlockIndexWriter.writeSingleLevelIndex(out, <span class="string">&quot;Bloom filter&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>其实还有部分元数据（各种offset和树的生成）没有分析。以后在说吧。</p>
<h2 id="HFileReaderV2"><a href="#HFileReaderV2" class="headerlink" title="HFileReaderV2"></a>HFileReaderV2</h2><p>由上述的代码分析来看，其实读取的时候最主要要解决的是是否读此block。决定了读此block之后已经没有太多需要在此文章中分析了，因为那是检索流程的事情（组织memstore和storefile）</p>
<ol>
<li>读block index和bloom filter信息</li>
<li>使用这两种索引过滤block</li>
</ol>
<p>HFileReader主要涉及到的几个方法，包括获取和open。发生在在检索获取scanner和过滤scanner时。</p>
<p>在List<KeyValueScanner> HStore.getScanners(boolean cacheBlocks, boolean isGet, boolean usePread, boolean isCompaction, ScanQueryMatcher matcher, byte[] startRow, byte[] stopRow, long readPt)中如下代码，获取此store中的file对应的scanner。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List&lt;StoreFileScanner&gt; sfScanners = StoreFileScanner.getScannersForStoreFiles(storeFilesToScan, cacheBlocks, usePread, isCompaction, <span class="literal">false</span>, matcher, readPt);</span><br></pre></td></tr></table></figure>

<p>此方法调用了如下方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//此方法会调用Open方法</span></span><br><span class="line">StoreFile.<span class="type">Reader</span> <span class="variable">r</span> <span class="operator">=</span> file.createReader(canUseDrop);</span><br></pre></td></tr></table></figure>

<p>接着调用open方法，方法如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">if</span> (<span class="built_in">this</span>.reader != <span class="literal">null</span>) &#123;</span><br><span class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalAccessError</span>(<span class="string">&quot;Already open&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Open the StoreFile.Reader</span></span><br><span class="line">   <span class="built_in">this</span>.reader = fileInfo.open(<span class="built_in">this</span>.fs, <span class="built_in">this</span>.cacheConf, canUseDropBehind);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Load up indices and fileinfo. This also loads Bloom filter type.</span></span><br><span class="line">   metadataMap = Collections.unmodifiableMap(<span class="built_in">this</span>.reader.loadFileInfo());</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Read in our metadata.</span></span><br><span class="line">   <span class="type">byte</span> [] b = metadataMap.get(MAX_SEQ_ID_KEY);</span><br><span class="line">   <span class="keyword">if</span> (b != <span class="literal">null</span>) &#123;</span><br><span class="line">     <span class="comment">// By convention, if halfhfile, top half has a sequence number &gt; bottom</span></span><br><span class="line">     <span class="comment">// half. Thats why we add one in below. Its done for case the two halves</span></span><br><span class="line">     <span class="comment">// are ever merged back together --rare.  Without it, on open of store,</span></span><br><span class="line">     <span class="comment">// since store files are distinguished by sequence id, the one half would</span></span><br><span class="line">     <span class="comment">// subsume the other.</span></span><br><span class="line">     <span class="built_in">this</span>.sequenceid = Bytes.toLong(b);</span><br><span class="line">     <span class="keyword">if</span> (fileInfo.isTopReference()) &#123;</span><br><span class="line">       <span class="built_in">this</span>.sequenceid += <span class="number">1</span>;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (isBulkLoadResult())&#123;</span><br><span class="line">     <span class="comment">// generate the sequenceId from the fileName</span></span><br><span class="line">     <span class="comment">// fileName is of the form &lt;randomName&gt;_SeqId_&lt;id-when-loaded&gt;_</span></span><br><span class="line">     <span class="type">String</span> <span class="variable">fileName</span> <span class="operator">=</span> <span class="built_in">this</span>.getPath().getName();</span><br><span class="line">     <span class="comment">// Use lastIndexOf() to get the last, most recent bulk load seqId.</span></span><br><span class="line">     <span class="type">int</span> <span class="variable">startPos</span> <span class="operator">=</span> fileName.lastIndexOf(<span class="string">&quot;SeqId_&quot;</span>);</span><br><span class="line">     <span class="keyword">if</span> (startPos != -<span class="number">1</span>) &#123;</span><br><span class="line">       <span class="built_in">this</span>.sequenceid = Long.parseLong(fileName.substring(startPos + <span class="number">6</span>,</span><br><span class="line">           fileName.indexOf(<span class="string">&#x27;_&#x27;</span>, startPos + <span class="number">6</span>)));</span><br><span class="line">       <span class="comment">// Handle reference files as done above.</span></span><br><span class="line">       <span class="keyword">if</span> (fileInfo.isTopReference()) &#123;</span><br><span class="line">         <span class="built_in">this</span>.sequenceid += <span class="number">1</span>;</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="built_in">this</span>.reader.setBulkLoaded(<span class="literal">true</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="built_in">this</span>.reader.setSequenceID(<span class="built_in">this</span>.sequenceid);</span><br><span class="line"></span><br><span class="line">   b = metadataMap.get(HFileWriterV2.MAX_MEMSTORE_TS_KEY);</span><br><span class="line">   <span class="keyword">if</span> (b != <span class="literal">null</span>) &#123;</span><br><span class="line">     <span class="built_in">this</span>.maxMemstoreTS = Bytes.toLong(b);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   b = metadataMap.get(MAJOR_COMPACTION_KEY);</span><br><span class="line">   <span class="keyword">if</span> (b != <span class="literal">null</span>) &#123;</span><br><span class="line">     <span class="type">boolean</span> <span class="variable">mc</span> <span class="operator">=</span> Bytes.toBoolean(b);</span><br><span class="line">     <span class="keyword">if</span> (<span class="built_in">this</span>.majorCompaction == <span class="literal">null</span>) &#123;</span><br><span class="line">       <span class="built_in">this</span>.majorCompaction = <span class="keyword">new</span> <span class="title class_">AtomicBoolean</span>(mc);</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="built_in">this</span>.majorCompaction.set(mc);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     <span class="comment">// Presume it is not major compacted if it doesn&#x27;t explicity say so</span></span><br><span class="line">     <span class="comment">// HFileOutputFormat explicitly sets the major compacted key.</span></span><br><span class="line">     <span class="built_in">this</span>.majorCompaction = <span class="keyword">new</span> <span class="title class_">AtomicBoolean</span>(<span class="literal">false</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   b = metadataMap.get(EXCLUDE_FROM_MINOR_COMPACTION_KEY);</span><br><span class="line">   <span class="built_in">this</span>.excludeFromMinorCompaction = (b != <span class="literal">null</span> &amp;&amp; Bytes.toBoolean(b));</span><br><span class="line"></span><br><span class="line"><span class="comment">//此出会读取bloom filter</span></span><br><span class="line">   <span class="type">BloomType</span> <span class="variable">hfileBloomType</span> <span class="operator">=</span> reader.getBloomFilterType();</span><br><span class="line">   <span class="keyword">if</span> (cfBloomType != BloomType.NONE) &#123;</span><br><span class="line">     reader.loadBloomfilter(BlockType.GENERAL_BLOOM_META);</span><br><span class="line">     <span class="keyword">if</span> (hfileBloomType != cfBloomType) &#123;</span><br><span class="line">       LOG.info(<span class="string">&quot;HFile Bloom filter type for &quot;</span></span><br><span class="line">           + reader.getHFileReader().getName() + <span class="string">&quot;: &quot;</span> + hfileBloomType</span><br><span class="line">           + <span class="string">&quot;, but &quot;</span> + cfBloomType + <span class="string">&quot; specified in column family &quot;</span></span><br><span class="line">           + <span class="string">&quot;configuration&quot;</span>);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (hfileBloomType != BloomType.NONE) &#123;</span><br><span class="line">     LOG.info(<span class="string">&quot;Bloom filter turned off by CF config for &quot;</span></span><br><span class="line">         + reader.getHFileReader().getName());</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// load delete family bloom filter</span></span><br><span class="line">   reader.loadBloomfilter(BlockType.DELETE_FAMILY_BLOOM_META);</span><br><span class="line"></span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     <span class="built_in">this</span>.reader.timeRange = TimeRangeTracker.getTimeRange(metadataMap.get(TIMERANGE_KEY));</span><br><span class="line">   &#125; <span class="keyword">catch</span> (IllegalArgumentException e) &#123;</span><br><span class="line">     LOG.error(<span class="string">&quot;Error reading timestamp range data from meta -- &quot;</span> +</span><br><span class="line">         <span class="string">&quot;proceeding without&quot;</span>, e);</span><br><span class="line">     <span class="built_in">this</span>.reader.timeRange = <span class="literal">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> <span class="built_in">this</span>.reader;</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<p>判断的一个文件是否需要读取时，在伟大的 boolean org.apache.hadoop.hbase.regionserver.StoreFileScanner.shouldUseScanner(Scan scan, SortedSet&lt;byte[]&gt; columns, long oldestUnexpiredTS) 方法中的如下方法使用了bloomfilter。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//此处使用bloomfilter过滤。在此方法中会调用bloomFilter.contains，在此contains会先使用block index 判断。</span></span><br><span class="line">reader.passesBloomFilter(scan, columns)</span><br></pre></td></tr></table></figure>

<p>里面会调用一个contains</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">//判断读取哪个block，rootBlockContaingKey里的blockKeys为chunk的个数。</span></span><br><span class="line"><span class="comment">//index是从bloommeta中读取，DataInput bloomMeta = reader.getGeneralBloomFilterMetadata(); 代码获取。</span></span><br><span class="line"><span class="type">int</span> <span class="variable">block</span> <span class="operator">=</span> index.rootBlockContainingKey(key, keyOffset, keyLength);</span><br><span class="line">   <span class="keyword">if</span> (block &lt; <span class="number">0</span>) &#123;</span><br><span class="line">     result = <span class="literal">false</span>; <span class="comment">// This key is not in the file.</span></span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     HFileBlock bloomBlock;</span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">       <span class="comment">// We cache the block and use a positional read.</span></span><br><span class="line">       <span class="comment">//读取那个chunk的bf</span></span><br><span class="line">       bloomBlock = reader.readBlock(index.getRootBlockOffset(block),</span><br><span class="line">           index.getRootBlockDataSize(block), <span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>,</span><br><span class="line">           BlockType.BLOOM_CHUNK);</span><br><span class="line">     &#125; <span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">       <span class="comment">// The Bloom filter is broken, turn it off.</span></span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(</span><br><span class="line">           <span class="string">&quot;Failed to load Bloom block for key &quot;</span></span><br><span class="line">               + Bytes.toStringBinary(key, keyOffset, keyLength), ex);</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="type">ByteBuffer</span> <span class="variable">bloomBuf</span> <span class="operator">=</span> bloomBlock.getBufferReadOnly();</span><br><span class="line">     result = ByteBloomFilter.contains(key, keyOffset, keyLength,</span><br><span class="line">         bloomBuf.array(), bloomBuf.arrayOffset() + bloomBlock.headerSize(),</span><br><span class="line">         bloomBlock.getUncompressedSizeWithoutHeader(), hash, hashCount);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>在如下方法(感觉时seekTO时，用于scan时指定了开始的rowkey，这样解释就合理了。在reader.passesBloomFilter中有判断是否时scan)中使用block index过滤了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BlockWithScanInfo org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.BlockIndexReader.loadDataBlockWithScanInfo(<span class="type">byte</span>[] key, <span class="type">int</span> keyOffset, <span class="type">int</span> keyLength, HFileBlock currentBlock, <span class="type">boolean</span> cacheBlocks, <span class="type">boolean</span> pread, <span class="type">boolean</span> isCompaction) <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<p>CompoundBloomFilter构造方法中读取Block index的数据。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/05/14/hbase-src-hfile/" data-id="clyh80jir000hs2600x0d2vq1" data-title="HBase源码系列之HFile" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hbase-src-compaction" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/05/09/hbase-src-compaction/" class="article-date">
  <time class="dt-published" datetime="2017-05-09T15:44:59.000Z" itemprop="datePublished">2017-05-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/05/09/hbase-src-compaction/">HBase源码系列之compaction</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>像hbase这种基于LSM的架构，compaction是其中很重要一个环节。</p>
<h2 id="触发compaction"><a href="#触发compaction" class="headerlink" title="触发compaction"></a>触发compaction</h2><ol>
<li><p>手工出发</p>
</li>
<li><p>chore线程</p>
<ol>
<li>CompactionChecker里判断 「s.needsCompaction() 和 s.isMajorCompaction()」</li>
</ol>
</li>
<li><p>flush触发</p>
</li>
</ol>
<h2 id="执行compaction"><a href="#执行compaction" class="headerlink" title="执行compaction"></a>执行compaction</h2><p>​	此处才是本文的重点，上面的触发更多是条件的判断，不过也很重要（对于线上系统的运维和问题定位解决）此张章节会来较详细讨论HBase的compaction的有关源码方面的一些记录。</p>
<p>​	首先调用的是如下方法，生成CompactionContext构造CompactionRunner放入线程池中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">synchronized</span> CompactionRequest <span class="title function_">requestCompactionInternal</span><span class="params">(<span class="keyword">final</span> HRegion r, <span class="keyword">final</span> Store s,</span></span><br><span class="line"><span class="params">      <span class="keyword">final</span> String why, <span class="type">int</span> priority, CompactionRequest request, <span class="type">boolean</span> selectNow, User user)</span></span><br></pre></td></tr></table></figure>

<p>​	在里面调用</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">completed</span> <span class="operator">=</span> region.compact(compaction, store, compactionThroughputController, user);</span><br></pre></td></tr></table></figure>

<p>​	然后调用相应store的compact方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">store.compact(compaction, throughputController, user);</span><br></pre></td></tr></table></figure>

<p>​	里面一个compact操作具体的步骤如下：</p>
<p>​	1. 开始合并返回合并的结果。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Path&gt; newFiles = compaction.compact(throughputController, user);</span><br></pre></td></tr></table></figure>

<p>​	此方法中一个判断是否是major</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ScanType</span> <span class="variable">scanType</span> <span class="operator">=</span> scannerFactory.getScanType(request);</span><br></pre></td></tr></table></figure>

<p>​	此ScanType传递给了ScanQueryMatcher来做scan类型的判断。</p>
<p>​	2. 结果写入对应的cf的目录中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sfs = moveCompatedFilesIntoPlace(cr, newFiles, user);</span><br></pre></td></tr></table></figure>

<p>​	3. 将本次compaction写入HLOG中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writeCompactionWalRecord(filesToCompact, sfs);</span><br></pre></td></tr></table></figure>

<p>​	4. 更新StoreFileManager的storefiles，去除旧的文件，加入新的文件</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replaceStoreFiles(filesToCompact, sfs);</span><br></pre></td></tr></table></figure>

<p>​	5. 此时已经可以安心的文件读取了，最后一步骤就是删除旧的数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">completeCompaction(filesToCompact); </span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/05/09/hbase-src-compaction/" data-id="clyh80jir000cs260ca6b5xk5" data-title="HBase源码系列之compaction" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-HBase-trap" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/05/05/HBase-trap/" class="article-date">
  <time class="dt-published" datetime="2017-05-05T14:29:12.000Z" itemprop="datePublished">2017-05-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/05/05/HBase-trap/">HBase的一些坑</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>最近遇到了一些hbase的坑，先记录一下。</p>
<ol>
<li><p>mvcc的坑：在前几天的同事的一次调试，使用的put的指定了ts &#x3D;&gt; 想再测一次就删除了 &#x3D;&gt; 这些数据再次加入hbase查不到。 因为hbase的多版本方式不删除数据，所以在major_compact之前，delete的这个操作是保存在hbase中的。在这种情况下，如果新加入的数据的ts不必delete大时，会被hbase认为这些数据应该被删除。（不过这个感觉很比较，可以使用mvcc的版本来解决操作请求的顺序，而不出现delete后加入的数据的不能被显示出来）</p>
</li>
<li><p>有时候重启regionserver需要有些region没有上线，需要执行hbase hbck -repair，此命令很危险。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/05/05/HBase-trap/" data-id="clyh80jip0003s260hz3g67sg" data-title="HBase的一些坑" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-balance-in-hdfs" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/04/26/balance-in-hdfs/" class="article-date">
  <time class="dt-published" datetime="2017-04-26T15:33:10.000Z" itemprop="datePublished">2017-04-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/04/26/balance-in-hdfs/">hdfs balance的一些解读和问题记录</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>##balance过程的解读</p>
<ol>
<li><p>准备工作<br>获取的namenode</p>
</li>
<li><p>调用Balancer.run L1422，开始迭代<br>一个循环（除了2.1的返回结果ReturnStatus.IN_PROGRESS 继续之外，其他都结束）</p>
</li>
</ol>
<p> 2.1 ReturnStatus r &#x3D; b.run L1352</p>
<p> ​	2.1.1 initNode获取需要移动的字节数bytesLeftToMove<br> ​			计算平均使用率<br> ​			计算出过载和未充分利用的节点需要移动的字节数，两者选取较大值（已排除在与平均值相差在threshold内的节点）<br> ​	2.1.2 chooseNode获取决定要移动的字节<br>             chooseDatanodes: 三种匹配类型Matcher选取（同一组，同一机架，剩下的），每一类型做如下类型操作</p>
<p>​	1. 处理过载到未好好利用的。 2. 处理过载到使用少的。 3. 处理多使用到少使用</p>
<p>​	chooseCandidate对于每个源节点，选个候选节点（如果能符合匹配规则Matcher就选择他）<br>​				matchSourceWithTargetToMove选择两者能移动的少的字节数，形成NodeTask<br>​	2.1.3 dispatchBlockMoves L1103启动线程去移动数据，处理NodeTask<br>​		{两个条件会结束noPendingBlockIteration &gt;&#x3D; MAX_NO_PENDING_BLOCK_ITERATIONS 和Time.now()-				startTime &gt; MAX_ITERATION_TIME}<br>​		dispatchBlocks L614 为每个source启动一个线程去移动数据(线程放入dispatcherExecutor线程池)，然后等待回复<br>​		此处一轮迭代有时间限制<br>​			dispatcherExecutor.submit(source.new BlockMoveDispatcher());(调用dispatchBlocks())<br>​				chooseNextBlockToMove 获取下一步需要移动block，选择的代理节点是拥有此block但是传递到target比较好。<br>​				此处有一个5个任务的限制，难怪增大timeout的时间之后不会quota is exceeded***<br>​					chooseBlockAndProxy 选择块和代理节点<br>​						isGoodBlockCandidate 选择好的块<br>​						chooseProxySource 在选中的块中选择一个和target比较好的location<br>​				scheduleBlockMove 发送到代理节点并给代理节点的发送复制请求<br>​					dispatch() 发送数据(<em><strong>此处看代码不是异步处理，果然不是</strong></em>)<br>​					在目的节点DataXceiver.replaceBlock方法接受来自proxy的block发送流<br>​						在此处有balanceThrottler限制<br>​				filterMovedBlocks 过滤<br>​				判断需要不需要更多的block<br>​			waitForMoveCompletion()等待所有targets里的pending任务结束(如果没有结束此处会等待)<br>​	shouldContinue如果移动字节数(dispatchBlockMoves结果)大于零或等于零次数少于	MAX_NOT_CHANGED_ITERATIONS就是in_progress<br>2.2 resetData清楚数据，为再来一次循环做准备<br>2.3 根据r判断是否结束，判断条件在上面</p>
<p>简单概括</p>
<pre><code>--&gt; 计算那些需要移动的节点 
--&gt; 在此节点中选择想要移动的block 
--&gt; 对此block选择一个proxy（此proxy也有这个block的副本，并且传输起来比较好） 
--&gt; 建立任务（向target节点发送replaceBlock请求，target节点向proxy节点发送copyBlock请求）拷贝数据
</code></pre>
<h2 id="问题与解决"><a href="#问题与解决" class="headerlink" title="问题与解决"></a>问题与解决</h2><ol>
<li>balancer节点发送请求会有超时，在日志文件中报Read timed out -&gt; 日志会报线程数超出配额 -&gt; 提早退出balance过程，这种情况是balancer节点和target节点之间的rpc断开连接。只要改大超时设置就可以了（不清楚为啥不把超时统一到那个配置，并且hdfs把那些异常处理不打印问题，这个处理方式也很奇怪，可能新版本有改进）。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/04/26/balance-in-hdfs/" data-id="clyh80jiq0007s26060lbc1qy" data-title="hdfs balance的一些解读和问题记录" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hdfs/" rel="tag">hdfs</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/4/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/6/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ability/" rel="tag">ability</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bank-reading/" rel="tag">bank, reading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/career/" rel="tag">career</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/career-reading/" rel="tag">career,reading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/" rel="tag">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gc/" rel="tag">gc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hdfs/" rel="tag">hdfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java-concurrent/" rel="tag">java, concurrent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/job/" rel="tag">job</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/" rel="tag">life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life-reading/" rel="tag">life,reading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mvn/" rel="tag">mvn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paldb/" rel="tag">paldb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper/" rel="tag">paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rcfile/" rel="tag">rcfile</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reading/" rel="tag">reading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring/" rel="tag">spring</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/src/" rel="tag">src</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/src-treemap/" rel="tag">src, treemap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/summary/" rel="tag">summary</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/writing/" rel="tag">writing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zk/" rel="tag">zk</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ability/" style="font-size: 10px;">ability</a> <a href="/tags/bank-reading/" style="font-size: 10px;">bank, reading</a> <a href="/tags/career/" style="font-size: 10px;">career</a> <a href="/tags/career-reading/" style="font-size: 10px;">career,reading</a> <a href="/tags/flume/" style="font-size: 10px;">flume</a> <a href="/tags/gc/" style="font-size: 10px;">gc</a> <a href="/tags/hadoop/" style="font-size: 12.5px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 20px;">hbase</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/java-concurrent/" style="font-size: 10px;">java, concurrent</a> <a href="/tags/job/" style="font-size: 10px;">job</a> <a href="/tags/kafka/" style="font-size: 12.5px;">kafka</a> <a href="/tags/life/" style="font-size: 20px;">life</a> <a href="/tags/life-reading/" style="font-size: 10px;">life,reading</a> <a href="/tags/mvn/" style="font-size: 10px;">mvn</a> <a href="/tags/paldb/" style="font-size: 10px;">paldb</a> <a href="/tags/paper/" style="font-size: 10px;">paper</a> <a href="/tags/rcfile/" style="font-size: 10px;">rcfile</a> <a href="/tags/reading/" style="font-size: 17.5px;">reading</a> <a href="/tags/spring/" style="font-size: 10px;">spring</a> <a href="/tags/src/" style="font-size: 10px;">src</a> <a href="/tags/src-treemap/" style="font-size: 10px;">src, treemap</a> <a href="/tags/summary/" style="font-size: 10px;">summary</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/zk/" style="font-size: 10px;">zk</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/07/11/%E5%81%9A%E4%BA%8B%E6%96%B9%E5%BC%8F/">做事方式</a>
          </li>
        
          <li>
            <a href="/2024/07/11/%E6%8A%95%E8%B5%84%E4%BD%93%E7%B3%BB/">投资体系</a>
          </li>
        
          <li>
            <a href="/2024/07/11/%E5%AD%A6%E4%BC%9A%E5%88%86%E8%A7%A3%E4%BB%BB%E5%8A%A1/">学会分解任务</a>
          </li>
        
          <li>
            <a href="/2024/07/11/%E5%81%9A%E5%86%B3%E5%AE%9A%E7%9A%84%E6%96%B9%E5%BC%8F/">做决定的方式</a>
          </li>
        
          <li>
            <a href="/2024/07/11/%E8%B4%A1%E7%8C%AE%E7%A1%AE%E5%AE%9A%E6%80%A7/">贡献确定性</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 binbin liu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>